# app.py
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Dict
import os, json, requests, concurrent.futures, logging, re

app = FastAPI()
log = logging.getLogger("uvicorn.error")

# â”€â”€â”€ OpenAI ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
OPENAI_KEY = "example"
HEADERS = {"Authorization": f"Bearer {OPENAI_KEY}",
           "Content-Type": "application/json"}
MODEL = "gpt-4o-mini"

# GPT ì‘ë‹µì´ ```json ...``` ì½”ë“œë¸”ë¡ì¼ ë•Œ ì œê±°í•˜ëŠ” ì •ê·œì‹
CODEBLOCK_RE = re.compile(r"```(?:json)?\s*(\{.*?\})\s*```", re.S)

PROMPT = """
ì´ ì‚¬ì§„ì€ ì˜¤ëŠ˜ ì‚¬ìš©ìê°€ ì°ì€ ì¼ìƒì‚¬ì§„ ì¤‘ì— í•˜ë‚˜ì•¼. 
                                ì´ ì‚¬ìš©ìì˜ ì¼ê¸°ë¥¼ ì‘ì„±í•  ìˆ˜ ìˆë„ë¡ ì´ë•Œì˜ ìŠ¤í† ë¦¬ë¥¼ ëŒì–´ë‚¼ ë§Œí•œ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ëŠ”ë° ì˜ë„ëŠ” ê°ì •ì„ ëŒì–´ë‚´ëŠ” ê²ƒì´ì•¼., 
                                í•´ë‹¹ ì‚¬ì§„ì˜ ì£¼ìš” ë””í…Œì¼ê³¼ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë‹´ì€ ìº¡ì…˜ë„ í•¨ê»˜ ì œê³µë˜ì–´. 
                                ì´ ìº¡ì…˜ì„ ì°¸ê³ í•˜ì—¬, ê° ì‚¬ì§„ë‹¹ ì§ˆë¬¸ì€ 1ê°œë§Œ ìƒì„±í•´ì£¼ê³ , ì˜ˆì‹œë‹µë³€ë„ ê°ê´€ì‹ 4ì§€ì„ ë‹¤ë¡œ ì œê³µí•´ì£¼ê³  ì´ëª¨ì§€ë„ í¬í•¨í•´ì¤˜. 
                                ê·¸ëŸ¬ë¯€ë¡œ ì‚¬ì§„ì´ 3ê°œë©´ ì§ˆë¬¸ê³¼ ì˜ˆì‹œë‹µë³€ì„¸íŠ¸ë„ 3ê°œì”© ìƒì„±ë˜ì–´ì•¼í•´. 
                                ì¶œë ¥ì€ ë°˜ë“œì‹œ JSON í˜•ì‹ë§Œ í¬í•¨ë˜ì–´ì•¼ í•˜ë©°, ì¶”ê°€ì ì¸ ì„¤ëª…ì´ë‚˜ í…ìŠ¤íŠ¸ëŠ” ì—†ì–´ì•¼í•´. ì•„ë˜ ì˜ˆì‹œë¥¼ ì°¸ê³ í•´ì¤˜. 
                                 {
                                        "title": "ì „í†µ ê±´ë¬¼", 
                                        "caption": "ë‚¡ì•˜ì§€ë§Œ ì•„ë¦„ë‹¤ìš´ ì „í†µ ê±´ë¬¼ì˜ ë””í…Œì¼ê³¼ ì£¼ë³€ í’ê²½ì´ ë‹ë³´ì´ëŠ” ì‚¬ì§„",
                                        "question": "ì´ ì „í†µ ê±´ë¬¼ì„ ë³´ë©° ì–´ë–¤ ê°ì •ì„ ëŠê¼ˆë‚˜ìš”?",
                                        "options": [
                                        "ì—­ì‚¬ì  ì˜ë¯¸ë¥¼ ëŠê»´ì„œ ê°ë™í–ˆë‹¤.ğŸ˜š",
                                        "ê·¸ëƒ¥ ìŠ¤ì³ ì§€ë‚˜ê°”ë‹¤.ğŸ˜",
                                        "ì•„ë¦„ë‹¤ì›Œì„œ ì‚¬ì§„ì„ ì°ê³  ì‹¶ì—ˆë‹¤.ğŸ¤©",
                                        "ì™¸ë¡œì›€ì„ ëŠê¼ˆë‹¤.ğŸ¥²"
                                        ]
                                    },
                    
ì¶œë ¥ì€ ë°˜ë“œì‹œ JSON ê°ì²´ë§Œ í¬í•¨í•´ì•¼ í•˜ë©°, ì¶”ê°€ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ ë„£ì§€ ë§ˆ.
"""

# â”€â”€â”€ GPT í˜¸ì¶œ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def call_gpt_with_image(url: str) -> Dict:
    payload = {
        "model": MODEL,
        "messages": [{
            "role": "user",
            "content": [
                {"type": "text", "text": PROMPT},
                {"type": "image_url", "image_url": {"url": url}}
            ],
        }],
        "max_tokens": 800,
        # ëª¨ë¸ì´ ìˆœìˆ˜ JSONë§Œ ë³´ë‚´ë„ë¡ ê°•ì œ
        "response_format": {"type": "json_object"}
    }

    r = requests.post("https://api.openai.com/v1/chat/completions",
                      headers=HEADERS, json=payload, timeout=120)
    if r.status_code != 200:
        raise RuntimeError(f"OpenAI {r.status_code}: {r.text}")

    raw = r.json()["choices"][0]["message"]["content"].strip()

    # ì½”ë“œë¸”ë¡ ì œê±°(ëª¨ë¸ì´ ê·œê²© ì•ˆ ì§€ì¼°ì„ ë•Œ ëŒ€ë¹„)
    m = CODEBLOCK_RE.search(raw)
    if m:
        raw = m.group(1)
    data = json.loads(raw)

    # 'question' â†’ 'prompt' ë¡œ ì´ë¦„ êµì •
    if "question" in data:
        data["prompt"] = data.pop("question")
    return data

# â”€â”€â”€ Pydantic ëª¨ë¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class ImagesRequest(BaseModel):
    image_urls: List[str]

# â”€â”€â”€ ì—”ë“œí¬ì¸íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.post("/generate-question")
def generate_questions(req: ImagesRequest):
    max_workers = min(5, len(req.image_urls))   # ë™ì‹œ í˜¸ì¶œ ì œí•œ
    questions: List[Dict] = [None] * len(req.image_urls)

    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as ex:
        future_map = {
            ex.submit(call_gpt_with_image, url): idx
            for idx, url in enumerate(req.image_urls)
        }
        for fut in concurrent.futures.as_completed(future_map):
            idx = future_map[fut]
            try:
                questions[idx] = fut.result()
            except Exception as e:
                log.error("Error on %s: %s", req.image_urls[idx], e)
                raise HTTPException(502, f"{req.image_urls[idx]} â†’ {e}")

    return {"questions": questions}

@app.get("/health")
def health():
    return {"status": "ok"}
