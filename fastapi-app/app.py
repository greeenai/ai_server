# app.py
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Dict
import os, json, requests, concurrent.futures, logging, re
from dotenv import load_dotenv, find_dotenv
import os
app = FastAPI()
log = logging.getLogger("uvicorn.error")
load_dotenv(find_dotenv())


# â”€â”€â”€ OpenAI ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
OPENAI_KEY = os.getenv("OPENAI_API_KEY")
HEADERS = {"Authorization": f"Bearer {OPENAI_KEY}",
           "Content-Type": "application/json"}
MODEL = "gpt-4o-mini"

# GPT ì‘ë‹µì´ ```json ...``` ì½”ë“œë¸”ë¡ì¼ ë•Œ ì œê±°í•˜ëŠ” ì •ê·œì‹
CODEBLOCK_RE = re.compile(r"```(?:json)?\s*(\{.*?\})\s*```", re.S)

PROMPT = """
ì´ ì‚¬ì§„ì€ ì˜¤ëŠ˜ ì‚¬ìš©ìê°€ ì°ì€ ì¼ìƒì‚¬ì§„ ì¤‘ì— í•˜ë‚˜ì•¼. 
                                ì´ ì‚¬ìš©ìì˜ ì¼ê¸°ë¥¼ ì‘ì„±í•  ìˆ˜ ìˆë„ë¡ ì´ë•Œì˜ ìŠ¤í† ë¦¬ë¥¼ ëŒì–´ë‚¼ ë§Œí•œ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ëŠ”ë° ì˜ë„ëŠ” ê°ì •ì„ ëŒì–´ë‚´ëŠ” ê²ƒì´ì•¼., 
                                í•´ë‹¹ ì‚¬ì§„ì˜ ì£¼ìš” ë””í…Œì¼ê³¼ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë‹´ì€ ìº¡ì…˜ë„ í•¨ê»˜ ì œê³µë˜ì–´. 
                                ì´ ìº¡ì…˜ì„ ì°¸ê³ í•˜ì—¬, ê° ì‚¬ì§„ë‹¹ ì§ˆë¬¸ì€ 1ê°œë§Œ ìƒì„±í•´ì£¼ê³ , ì˜ˆì‹œë‹µë³€ë„ ê°ê´€ì‹ 4ì§€ì„ ë‹¤ë¡œ ì œê³µí•´ì£¼ê³  ì´ëª¨ì§€ë„ í¬í•¨í•´ì¤˜. 
                                ê·¸ëŸ¬ë¯€ë¡œ ì‚¬ì§„ì´ 3ê°œë©´ ì§ˆë¬¸ê³¼ ì˜ˆì‹œë‹µë³€ì„¸íŠ¸ë„ 3ê°œì”© ìƒì„±ë˜ì–´ì•¼í•´. 
                                ì¶œë ¥ì€ ë°˜ë“œì‹œ JSON í˜•ì‹ë§Œ í¬í•¨ë˜ì–´ì•¼ í•˜ë©°, ì¶”ê°€ì ì¸ ì„¤ëª…ì´ë‚˜ í…ìŠ¤íŠ¸ëŠ” ì—†ì–´ì•¼í•´. ì•„ë˜ ì˜ˆì‹œë¥¼ ì°¸ê³ í•´ì¤˜. 
                                 {
                                        "title": "ì „í†µ ê±´ë¬¼", 
                                        "caption": "ë‚¡ì•˜ì§€ë§Œ ì•„ë¦„ë‹¤ìš´ ì „í†µ ê±´ë¬¼ì˜ ë””í…Œì¼ê³¼ ì£¼ë³€ í’ê²½ì´ ë‹ë³´ì´ëŠ” ì‚¬ì§„",
                                        "question": "ì´ ì „í†µ ê±´ë¬¼ì„ ë³´ë©° ì–´ë–¤ ê°ì •ì„ ëŠê¼ˆë‚˜ìš”?",
                                        "options": [
                                        "ì—­ì‚¬ì  ì˜ë¯¸ë¥¼ ëŠê»´ì„œ ê°ë™í–ˆë‹¤.ğŸ˜š",
                                        "ê·¸ëƒ¥ ìŠ¤ì³ ì§€ë‚˜ê°”ë‹¤.ğŸ˜",
                                        "ì•„ë¦„ë‹¤ì›Œì„œ ì‚¬ì§„ì„ ì°ê³  ì‹¶ì—ˆë‹¤.ğŸ¤©",
                                        "ì™¸ë¡œì›€ì„ ëŠê¼ˆë‹¤.ğŸ¥²"
                                        ]
                                    },
                    
ì¶œë ¥ì€ ë°˜ë“œì‹œ JSON ê°ì²´ë§Œ í¬í•¨í•´ì•¼ í•˜ë©°, ì¶”ê°€ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ ë„£ì§€ ë§ˆ.
"""

# â”€â”€â”€ GPT í˜¸ì¶œ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def call_gpt_with_image(url: str) -> Dict:
    payload = {
        "model": MODEL,
        "messages": [{
            "role": "user",
            "content": [
                {"type": "text", "text": PROMPT},
                {"type": "image_url", "image_url": {"url": url}}
            ],
        }],
        "max_tokens": 800,
        # ëª¨ë¸ì´ ìˆœìˆ˜ JSONë§Œ ë³´ë‚´ë„ë¡ ê°•ì œ
        "response_format": {"type": "json_object"}
    }

    r = requests.post("https://api.openai.com/v1/chat/completions",
                      headers=HEADERS, json=payload, timeout=120)
    if r.status_code != 200:
        raise RuntimeError(f"OpenAI {r.status_code}: {r.text}")

    raw = r.json()["choices"][0]["message"]["content"].strip()

    # ì½”ë“œë¸”ë¡ ì œê±°(ëª¨ë¸ì´ ê·œê²© ì•ˆ ì§€ì¼°ì„ ë•Œ ëŒ€ë¹„)
    m = CODEBLOCK_RE.search(raw)
    if m:
        raw = m.group(1)
    data = json.loads(raw)

    # 'question' â†’ 'prompt' ë¡œ ì´ë¦„ êµì •
    if "question" in data:
        data["prompt"] = data.pop("question")
    return data


# â”€â”€â”€ Pydantic ëª¨ë¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class ImagesRequest(BaseModel):
    image_urls: List[str]
    
class DiaryEntry(BaseModel):
    title: str
    caption: str
    question: str
    answer: str  

class DiaryRequest(BaseModel):
    entries: List[DiaryEntry]
    
    
def call_gpt_diary(entries: List[DiaryEntry]) -> str:
    diary_prompt = (
    "ë‹¹ì‹ ì€ ê°ì • ì €ë„ë§ì„ ë•ëŠ” ì—ì„¸ì´ ì‘ê°€ì…ë‹ˆë‹¤. "
    "ë‹¤ìŒ JSON ë°°ì—´ì—ëŠ” ì‚¬ìš©ìê°€ ì˜¤ëŠ˜ ì°ì€ ì‚¬ì§„ë§ˆë‹¤ â“title(í‚¤ì›Œë“œ), â“‘caption(ë¬˜ì‚¬), "
    "â“’question(ì§ˆë¬¸), â““answer(ì‚¬ìš©ìê°€ ê³ ë¥¸ ê°ê´€ì‹ ë‹µë³€)ì´ ë“¤ì–´ ìˆìŠµë‹ˆë‹¤. "
    "\n\n"
    "ğŸ–‹ï¸ **ëª©í‘œ**\n"
    "  â€¢ ê° í•­ëª©ì˜ question-answer ìŒê³¼ caption ì† ë””í…Œì¼ì„ ì—®ì–´, ì‚¬ìš©ìì˜ í•˜ë£¨ë¥¼ ë˜ì§šëŠ” 4-5ì¤„ì§œë¦¬ ì¼ê¸°ë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n"
    "  â€¢ í•˜ë£¨ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ íë¦„ìœ¼ë¡œ ì—°ê²°í•˜ë˜, ì‚¬ì§„ ê°„ ì „í™˜ì€ ìì—°ìŠ¤ëŸ¬ìš´ ì ‘ì†ì‚¬ë‚˜ ì‹œê°„ìˆœ ì„œìˆ ë¡œ ì´ì–´ì£¼ì„¸ìš”.\n"
    "  â€¢ ì‹œê°Â·ì²­ê°Â·í›„ê° ë“± ê°ê° ë¬˜ì‚¬ë¥¼ í•œë‘ êµ°ë° ë„£ì–´ ìƒë™ê°ì„ ì£¼ê³ , ì‚¬ìš©ìì˜ ë‚´ë©´ ê°ì •(why)ì— ì§§ê²Œ ë°˜ì¶”í•˜ì„¸ìš”.\n"
    "  â€¢ ê¸€ ì‚¬ì´ì— 2-3ê°œì˜ ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì„ì–´ ê°ì •ì„ ë“œëŸ¬ë‚´ë˜, ê³¼ë„í•˜ê²Œ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.\n"
    "\n"
    "ğŸš« **í˜•ì‹ ê·œì¹™**\n"
    "  â€¢ ë²ˆí˜¸, ë”°ì˜´í‘œ, ë¦¬ìŠ¤íŠ¸, í—¤ë”, ë§ˆí¬ë‹¤ìš´ì€ ì“°ì§€ ë§ˆì„¸ìš”. ìˆœìˆ˜ ì„œìˆ í˜• ë‹¨ë½ë§Œ ì‘ì„±í•©ë‹ˆë‹¤.\n"
    "  â€¢ ì¶œë ¥ì€ **ì¼ê¸° ë³¸ë¬¸ í…ìŠ¤íŠ¸ë§Œ** ë°˜í™˜í•˜ê³ , ê·¸ ì™¸ ì„¤ëª…Â·ì£¼ì„Â·ì½”ë“œë¸”ë¡ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.\n"
)   

    photos_json = json.dumps([e.dict() for e in entries], ensure_ascii=False, indent=2)

    payload = {
        "model": MODEL,
        "messages": [
            {"role": "user", "content": diary_prompt},
            {"role": "user", "content": f"[ì‚¬ì§„ ê¸°ë¡]\n{photos_json}"}
        ],
        "max_tokens": 400,
        "response_format": {"type": "text"}
    }

    r = requests.post("https://api.openai.com/v1/chat/completions",
                      headers=HEADERS, json=payload, timeout=120)
    r.raise_for_status()
    return r.json()["choices"][0]["message"]["content"].strip()


    
# â”€â”€â”€ ì—”ë“œí¬ì¸íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.post("/generate-question")
def generate_questions(req: ImagesRequest):
    max_workers = min(5, len(req.image_urls))   # ë™ì‹œ í˜¸ì¶œ ì œí•œ
    questions: List[Dict] = [None] * len(req.image_urls)

    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as ex:
        future_map = {
            ex.submit(call_gpt_with_image, url): idx
            for idx, url in enumerate(req.image_urls)
        }
        for fut in concurrent.futures.as_completed(future_map):
            idx = future_map[fut]
            try:
                questions[idx] = fut.result()
            except Exception as e:
                log.error("Error on %s: %s", req.image_urls[idx], e)
                raise HTTPException(502, f"{req.image_urls[idx]} â†’ {e}")

    return {"questions": questions}

@app.post("/generate-diary")
def generate_diary(req: DiaryRequest):
    try:
        diary = call_gpt_diary(req.entries)
    except Exception as e:
        log.error("Diary generation error: %s", e)
        raise HTTPException(502, str(e))
    return {"diary": diary}

@app.get("/health")
def health():
    return {"status": "ok"}
