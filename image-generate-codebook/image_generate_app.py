"""
# image_generate_app.py

ì‚¬ìš© ì˜ˆì‹œ cli ëª…ë ¹ì–´:
uvicorn image_generate_app:app --host 0.0.0.0 --port 8000 --reload

Diary Entry â†’ í”„ë¡¬í”„íŠ¸ â†’ SDXL ì´ë¯¸ì§€ ìƒì„± ì„œë¹„ìŠ¤

ë‹¤ì´ì–´ë¦¬ ì—”íŠ¸ë¦¬(ì œëª©, ìº¡ì…˜, ì§ˆë¬¸, ë‹µë³€)ë¥¼ ë°›ì•„ GPT-4o-minië¡œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•˜ê³ ,
ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Stable Diffusion XL ëª¨ë¸ì„ í†µí•´ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” FastAPI ì„œë²„
"""

import io
import time
import asyncio
import os
from pathlib import Path
from typing import List

import torch
import openai
import numpy as np
from fastapi import FastAPI, HTTPException
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field
from PIL import Image
from diffusers import StableDiffusionXLPipeline
from fastapi.concurrency import run_in_threadpool

# ================================================================================
# í™˜ê²½ ì„¤ì •
# ================================================================================

# CUDA ë©”ëª¨ë¦¬ ë¶„í•  ì„¤ì •ìœ¼ë¡œ Out of Memory ì˜¤ë¥˜ ë°©ì§€
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "max_split_size_mb:32"
torch.set_printoptions(precision=10)  # ë””ë²„ê¹… ì‹œ ì •ë°€ë„ í‘œì‹œ ì„¤ì •

# ìƒìˆ˜ ì •ì˜
STYLE_PREFIX = "cloud-bread style, "  # ëª¨ë“  í”„ë¡¬í”„íŠ¸ì— ì ìš©í•  ìŠ¤íƒ€ì¼ í”„ë¦¬í”½ìŠ¤
NEGATIVE_PROMPT = "low quality, blurry, distorted"  # ë¶€ì •ì  í”„ë¡¬í”„íŠ¸
OUT_DIR = Path("fast_api_output")
OUT_DIR.mkdir(exist_ok=True)  # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±

# ================================================================================
# ëª¨ë¸ ì´ˆê¸°í™”
# ================================================================================

def initialize_pipeline() -> StableDiffusionXLPipeline:
    """
    Stable Diffusion XL íŒŒì´í”„ë¼ì¸ì„ ì´ˆê¸°í™”í•˜ê³  ìµœì í™” ì„¤ì •ì„ ì ìš©
    
    Returns:
        StableDiffusionXLPipeline: ì´ˆê¸°í™”ëœ íŒŒì´í”„ë¼ì¸ ê°ì²´
    """
    # ì•ˆì •ì„±ì„ ìœ„í•´ ëª…ì‹œì ìœ¼ë¡œ float32 ì‚¬ìš©
    pipe = StableDiffusionXLPipeline.from_pretrained(
        "stabilityai/stable-diffusion-xl-base-1.0",
        torch_dtype=torch.float32,
        use_safetensors=True
    ).to("cuda")
    
    # Cloud-bread ìŠ¤íƒ€ì¼ LoRA ê°€ì¤‘ì¹˜ ì ìš©
    try:
        pipe.load_lora_weights("pytorch_lora_weights.safetensors")
        pipe.fuse_lora()  # LoRA ê°€ì¤‘ì¹˜ë¥¼ ëª¨ë¸ì— ê²°í•©
    except Exception as e:
        print(f"LoRA ê°€ì¤‘ì¹˜ ë¡œë”© ì˜¤ë¥˜: {e}")
    
    # ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì •
    pipe.enable_vae_tiling()  # VAE íƒ€ì¼ë§ìœ¼ë¡œ ëŒ€í˜• ì´ë¯¸ì§€ ì²˜ë¦¬ ìµœì í™”
    pipe.enable_attention_slicing()  # ì–´í…ì…˜ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ
    
    return pipe

# ì„œë²„ ì‹œì‘ ì‹œ íŒŒì´í”„ë¼ì¸ í•œ ë²ˆë§Œ ë¡œë“œ
try:
    PIPE = initialize_pipeline()
    print("âœ… Stable Diffusion XL íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì„±ê³µ")
except Exception as e:
    print(f"âŒ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    raise

# ================================================================================
# ë°ì´í„° ëª¨ë¸
# ================================================================================

class Entry(BaseModel):
    """ë‹¤ì´ì–´ë¦¬ ì—”íŠ¸ë¦¬ ë°ì´í„° ëª¨ë¸"""
    title: str
    caption: str
    question: str
    answer: str

class GenerateReq(BaseModel):
    """ì´ë¯¸ì§€ ìƒì„± ìš”ì²­ ë°ì´í„° ëª¨ë¸"""
    entries: List[Entry] = Field(..., min_items=1, description="ë‹¤ì´ì–´ë¦¬ ì—”íŠ¸ë¦¬ ëª©ë¡")

# ================================================================================
# í”„ë¡¬í”„íŠ¸ ìƒì„±
# ================================================================================

# GPT-4o-mini ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
PROMPT_SYSTEM = (
    "You are a prompt generator for Stable Diffusion. "
    "Given several diary entries (Korean caption + user emotional answer), "
    "produce ONE comma-separated English keyword prompt (~30 words) that blends the visual elements and mood. "
    "Return ONLY the prompt, no extra quotes or commentary."
)

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
aopenai = openai.AsyncOpenAI()

async def build_prompt(entries: List[Entry]) -> str:
    """
    ë‹¤ì´ì–´ë¦¬ ì—”íŠ¸ë¦¬ ëª©ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ GPT-4o-minië¥¼ ì‚¬ìš©í•´ ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ ìƒì„±
    
    Args:
        entries: ë‹¤ì´ì–´ë¦¬ ì—”íŠ¸ë¦¬ ëª©ë¡
        
    Returns:
        str: ìƒì„±ëœ Stable Diffusion í”„ë¡¬í”„íŠ¸
    """
    # ì—”íŠ¸ë¦¬ë³„ ìº¡ì…˜ê³¼ ê°ì • ë‹µë³€ì„ êµ¬ì¡°í™”
    lines = [
        f"{i}. Caption: {e.caption}\n   Emotion: {e.answer.strip()}"
        for i, e in enumerate(entries, 1)
    ]
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ êµ¬ì„±
    user_msg = "Entries:\n" + "\n".join(lines) + "\nPrompt:"
    
    # GPT-4o-minië¡œ í”„ë¡¬í”„íŠ¸ ìƒì„±
    chat = await aopenai.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": PROMPT_SYSTEM},
            {"role": "user", "content": user_msg},
        ],
        max_tokens=120,
        temperature=0.9,  # ì°½ì˜ì„± ì¡°ì ˆ
    )
    
    return chat.choices[0].message.content.strip()

# ================================================================================
# ì´ë¯¸ì§€ ìƒì„±
# ================================================================================

def post_process_image(img_array: np.ndarray) -> np.ndarray:
    """
    ì´ë¯¸ì§€ ë°°ì—´ì˜ ì´ìƒê°’(NaN) ë° ë²”ìœ„ë¥¼ ìˆ˜ì •í•˜ì—¬ ì•ˆì •ì ì¸ ì´ë¯¸ì§€ ìƒì„±
    
    Args:
        img_array: ì›ë³¸ ì´ë¯¸ì§€ ë°°ì—´
        
    Returns:
        np.ndarray: í›„ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ë°°ì—´
    """
    # NaN ê°’ í™•ì¸ ë° ì²˜ë¦¬
    if np.isnan(img_array).any():
        print("âš ï¸ ê²½ê³ : ì´ë¯¸ì§€ì— NaN ê°’ ë°œê²¬, ë³´ì • ì¤‘...")
        img_array = np.nan_to_num(img_array)
    
    # ë²”ìœ„ í™•ì¸ ë° ì¡°ì • (0-255 ë²”ìœ„ë¡œ)
    img_array = np.clip(img_array, 0, 255)
    
    return img_array.astype('uint8')

def generate_image(
    prompt: str,
    steps: int = 35, 
    scale: float = 7.0,
    w: int = 768, 
    h: int = 768
) -> Image.Image:
    """
    Stable Diffusion XLì„ ì‚¬ìš©í•˜ì—¬ ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ë¡œ ì´ë¯¸ì§€ ìƒì„±
    
    Args:
        prompt: ì´ë¯¸ì§€ ìƒì„±ì— ì‚¬ìš©í•  í”„ë¡¬í”„íŠ¸
        steps: ì¶”ë¡  ë‹¨ê³„ ìˆ˜
        scale: ê°€ì´ë˜ìŠ¤ ìŠ¤ì¼€ì¼
        w: ì´ë¯¸ì§€ ë„ˆë¹„
        h: ì´ë¯¸ì§€ ë†’ì´
        
    Returns:
        Image.Image: ìƒì„±ëœ PIL ì´ë¯¸ì§€
    """
    # ìŠ¤íƒ€ì¼ í”„ë¦¬í”½ìŠ¤ ì¶”ê°€
    full_prompt = STYLE_PREFIX + prompt
    print(f"ğŸ“ í”„ë¡¬í”„íŠ¸: {full_prompt}")
    
    # ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ë¶ˆí•„ìš” (ì¶”ë¡ ë§Œ ìˆ˜í–‰)
    with torch.no_grad():
        result = PIPE(
            prompt=full_prompt,
            negative_prompt=NEGATIVE_PROMPT,
            guidance_scale=scale,
            num_inference_steps=steps,
            width=w,
            height=h,
        )
    
    img = result.images[0]
    
    # ì´ë¯¸ì§€ í›„ì²˜ë¦¬
    img_array = np.array(img)
    img_array = post_process_image(img_array)
    img = Image.fromarray(img_array)
    
    # ë””ë²„ê¹…ìš© ì´ë¯¸ì§€ ì €ì¥
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    fname = OUT_DIR / f"debug_{timestamp}.png"
    img.save(fname)
    print(f"ğŸ–¼ï¸ ë””ë²„ê·¸ ì´ë¯¸ì§€ ì €ì¥: {fname}")
    
    return img

# ================================================================================
# FastAPI ì„œë²„
# ================================================================================

app = FastAPI(
    title="Diary â†’ Prompt â†’ SDXL Image",
    description="ë‹¤ì´ì–´ë¦¬ ì—”íŠ¸ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Stable Diffusion XL ì´ë¯¸ì§€ ìƒì„± API",
    version="1.0.0"
)

@app.post("/generate-image", response_class=StreamingResponse)
async def generate(req: GenerateReq):
    """
    ë‹¤ì´ì–´ë¦¬ ì—”íŠ¸ë¦¬ë¥¼ ë°›ì•„ ì´ë¯¸ì§€ ìƒì„±
    
    1. GPTë¡œ Stable Diffusion í”„ë¡¬í”„íŠ¸ ìƒì„±
    2. Stable Diffusion XLë¡œ ì´ë¯¸ì§€ ìƒì„±
    3. PNG ì´ë¯¸ì§€ë¡œ ì‘ë‹µ
    
    Args:
        req: ë‹¤ì´ì–´ë¦¬ ì—”íŠ¸ë¦¬ ëª©ë¡ì´ í¬í•¨ëœ ìš”ì²­ ê°ì²´
        
    Returns:
        StreamingResponse: ìƒì„±ëœ ì´ë¯¸ì§€ íŒŒì¼
    """
    # 1) GPTë¡œ SD í”„ë¡¬í”„íŠ¸ ìƒì„±
    try:
        sd_prompt = await build_prompt(req.entries)
    except Exception as e:
        print(f"âŒ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        raise HTTPException(500, f"Prompt generation failed: {e}")

    print(f"ğŸ”„ [SD-Prompt] {sd_prompt}")

    # 2) Stable Diffusion XL ì´ë¯¸ì§€ ìƒì„± (ë¸”ë¡œí‚¹ ì‘ì—… â†’ ìŠ¤ë ˆë“œí’€ ì‹¤í–‰)
    try:
        img = await run_in_threadpool(generate_image, sd_prompt)
    except Exception as e:
        print(f"âŒ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")
        raise HTTPException(500, f"Image generation failed: {e}")

    # 3) PNG ì´ë¯¸ì§€ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ
    buf = io.BytesIO()
    try:
        img.save(buf, format="PNG")
        buf.seek(0)  # ë²„í¼ í¬ì¸í„°ë¥¼ ì‹œì‘ìœ¼ë¡œ ì´ë™
    except Exception as e:
        print(f"âŒ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {e}")
        raise HTTPException(500, f"Failed to save image: {e}")
    
    # íŒŒì¼ëª… ë° ì‘ë‹µ í—¤ë” ì„¤ì •
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    filename = f"diary_{timestamp}.png"
    
    return StreamingResponse(
        buf,
        media_type="image/png",
        headers={"Content-Disposition": f'inline; filename="{filename}"'}
    )

# ì„œë²„ ì‹¤í–‰ (uvicorn main:app --reload)
if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)